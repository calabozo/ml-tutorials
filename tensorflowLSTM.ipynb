{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start creating a series for training.\n",
    "\n",
    "y[0] = x[0]\n",
    "\n",
    "y[1] = x[1]\n",
    "\n",
    "y[2] = x[0]+x[1]\n",
    "\n",
    "\n",
    "We are going to create different trainning sequences with different startup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences X:\n",
      "[[ 3.  6.  2. 49. 24.  8. 40.  6. 28. 46. 33. 46. 30. 36. 24.  7. 10. 17.\n",
      "   9.  2.  5. 39. 36. 37. 33. 29. 10. 33. 42. 42.]\n",
      " [43.  5. 28. 12. 35. 27. 27. 27.  0. 11. 12. 26. 36. 35. 34. 11. 40. 49.\n",
      "   0. 39. 23.  9.  2. 37. 39. 38.  9.  1. 28. 22.]\n",
      " [17. 21. 38. 15.  1. 20. 12. 15. 19. 48. 43. 38. 41. 49. 21.  2. 12. 44.\n",
      "  40. 27.  9. 32. 49. 16. 49. 36. 27. 26. 15. 38.]\n",
      " [49. 33. 47. 19. 35. 38. 21. 42.  9. 33. 17. 35. 11.  7. 34. 35. 32.  2.\n",
      "  11. 23. 32. 30. 14. 31. 39. 23. 32. 46. 47. 29.]\n",
      " [ 0. 21. 21. 21. 32. 16. 48. 28. 20. 28. 23. 22. 41.  7. 37.  3. 44. 49.\n",
      "  14. 12. 43. 19. 23. 12. 49. 16. 31. 11. 38. 10.]\n",
      " [ 8. 24. 31. 46. 48. 10. 43.  3.  4. 13. 49.  1. 35. 24. 40. 20.  0. 24.\n",
      "  48. 47.  0. 17. 11. 33. 30. 16. 41. 11. 39. 23.]\n",
      " [28. 15. 17.  4. 40. 28. 34. 39. 18. 47. 23. 33. 32. 46. 19. 44. 28. 35.\n",
      "  33. 17. 34. 36. 42. 47. 41.  6. 29. 16.  4. 38.]]\n",
      "Sequences Y:\n",
      "[[ 3.  6.  8. 51. 73. 32. 48. 46. 34. 74. 79. 79. 76. 66. 60. 31. 17. 27.\n",
      "  26. 11.  7. 44. 75. 73. 70. 62. 39. 43. 75. 84.]\n",
      " [43.  5. 33. 40. 47. 62. 54. 54. 27. 11. 23. 38. 62. 71. 69. 45. 51. 89.\n",
      "  49. 39. 62. 32. 11. 39. 76. 77. 47. 10. 29. 50.]\n",
      " [17. 21. 59. 53. 16. 21. 32. 27. 34. 67. 91. 81. 79. 90. 70. 23. 14. 56.\n",
      "  84. 67. 36. 41. 81. 65. 65. 85. 63. 53. 41. 53.]\n",
      " [49. 33. 80. 66. 54. 73. 59. 63. 51. 42. 50. 52. 46. 18. 41. 69. 67. 34.\n",
      "  13. 34. 55. 62. 44. 45. 70. 62. 55. 78. 93. 76.]\n",
      " [ 0. 21. 42. 42. 53. 48. 64. 76. 48. 48. 51. 45. 63. 48. 44. 40. 47. 93.\n",
      "  63. 26. 55. 62. 42. 35. 61. 65. 47. 42. 49. 48.]\n",
      " [ 8. 24. 55. 77. 94. 58. 53. 46.  7. 17. 62. 50. 36. 59. 64. 60. 20. 24.\n",
      "  72. 95. 47. 17. 28. 44. 63. 46. 57. 52. 50. 62.]\n",
      " [28. 15. 32. 21. 44. 68. 62. 73. 57. 65. 70. 56. 65. 78. 65. 63. 72. 63.\n",
      "  68. 50. 51. 70. 78. 89. 88. 47. 35. 45. 20. 42.]]\n"
     ]
    }
   ],
   "source": [
    "num_seqs=7\n",
    "seq_len=30\n",
    "seqs_x=np.array([]).reshape(-1,seq_len)\n",
    "seqs_y=np.array([]).reshape(-1,seq_len)\n",
    "for i in xrange(num_seqs):\n",
    "    x=np.empty((0),dtype=np.float64)\n",
    "    for j in xrange(seq_len):\n",
    "        x=np.append(x,np.float64(np.random.randint(0,50)))\n",
    "\n",
    "    y=np.empty_like(x)\n",
    "    y[0]=x[0]\n",
    "    y[1]=x[1]\n",
    "    for j in xrange(2,len(x)):\n",
    "        y[j]=x[j]+x[j-1]\n",
    "    seqs_x=np.concatenate((seqs_x, np.reshape(x,(1,-1))))\n",
    "    seqs_y=np.concatenate((seqs_y, np.reshape(y,(1,-1))))\n",
    "    \n",
    "    \n",
    "\n",
    "print \"Sequences X:\"\n",
    "print seqs_x\n",
    "print \"Sequences Y:\"\n",
    "print seqs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "th = np.int(num_seqs*0.7)\n",
    "train_x= seqs_x[:th]\n",
    "test_x = seqs_x[th:]\n",
    "train_y= seqs_y[:th]\n",
    "test_y = seqs_y[th:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 10\n",
    "num_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#The input data is going to be [batch_size]\n",
    "x_data = tf.placeholder(tf.float32, [None, 1],\"x_data\")\n",
    "\n",
    "#The output data is going to be [batch_size, 1]\n",
    "y_real = tf.placeholder(tf.float32, [None, 1],\"y_real\")\n",
    "\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "\n",
    "\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(x_data, init_state)\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "gvs = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# We save the graph to analyze it in Tensorboard\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le'ts try with an example, yust one sample from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "0.17150217\n",
      "But it should be:\n",
      "43.0\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "o = sess.run([out], feed_dict={x_data: train_x[0:1,0].reshape(-1,1), \n",
    "                                      y_real:train_y[0:1,0].reshape(-1,1),\n",
    "                                      c_in:np_c, h_in:np_h})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4417.588\n",
      "912.04236\n",
      "222.94768\n",
      "125.8858\n",
      "57.600925\n",
      "50.0817\n",
      "74.85818\n",
      "28.053059\n",
      "7.297879\n",
      "21.0089\n",
      "8.8673115\n",
      "13.872299\n",
      "23.86504\n",
      "2.0798922\n",
      "2.675952\n",
      "25.015575\n",
      "6.814285\n",
      "83.88816\n",
      "39.195007\n",
      "15.484887\n"
     ]
    }
   ],
   "source": [
    "max_epocs=10000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(train_x.shape[1]):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={x_data: train_x[:,i].reshape(-1,1), \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%500 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check with the known sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output sequence is:\n",
      "[12.32107353 22.30460358 43.58792496 42.40033722 61.8417778  53.01939011\n",
      " 56.33670044 58.39256287 45.43508148 56.55605316 54.44507599 44.94801712\n",
      " 69.1426239  39.26014709 48.01186752 23.61235046 35.5365715  70.59922028\n",
      " 53.08533478 25.87182236 52.11916351 55.65919113 37.14069748 41.71841049\n",
      " 51.17979431 57.79838562 43.18199921 46.7674408  47.27316666 51.6287117 ]\n",
      "The real output sequence is:\n",
      "[ 0. 21. 42. 42. 53. 48. 64. 76. 48. 48. 51. 45. 63. 48. 44. 40. 47. 93.\n",
      " 63. 26. 55. 62. 42. 35. 61. 65. 47. 42. 49. 48.]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "seq_id=0\n",
    "\n",
    "out_seq=np.array([])\n",
    "for i in xrange(test_x.shape[1]):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={x_data: test_x[seq_id,i].reshape(-1,1),       \n",
    "                                                             c_in:np_c, h_in:np_h})\n",
    "    out_seq = np.append(out_seq,out_val)\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "\n",
    "print \"The estimated output sequence is:\"\n",
    "print out_seq\n",
    "print \"The real output sequence is:\"\n",
    "print test_y[seq_id,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences with N-dimensions\n",
    "\n",
    "We are going to start creating a series for training.\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "  y[0] &= x_0[0] \\\\\n",
    "  y[1] &= x_0[1] \\\\\n",
    "  y[2] &= x_0[0]+x_0[1]+x_1[2]+x_1[1]    \n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences X:\n",
      "[[[43. 31.]\n",
      "  [27. 17.]\n",
      "  [47.  0.]\n",
      "  [ 0.  0.]\n",
      "  [ 4. 17.]\n",
      "  [13. 36.]\n",
      "  [12. 45.]\n",
      "  [28. 19.]\n",
      "  [32. 42.]\n",
      "  [32. 43.]\n",
      "  [27. 17.]\n",
      "  [ 1.  0.]\n",
      "  [36. 38.]\n",
      "  [37. 37.]\n",
      "  [17. 10.]]\n",
      "\n",
      " [[29. 39.]\n",
      "  [37. 46.]\n",
      "  [38. 34.]\n",
      "  [ 2. 27.]\n",
      "  [37. 27.]\n",
      "  [20. 46.]\n",
      "  [19. 32.]\n",
      "  [46. 20.]\n",
      "  [19.  5.]\n",
      "  [ 5. 38.]\n",
      "  [ 7. 28.]\n",
      "  [ 8. 41.]\n",
      "  [24. 43.]\n",
      "  [ 9. 14.]\n",
      "  [44. 33.]]\n",
      "\n",
      " [[23.  3.]\n",
      "  [31. 37.]\n",
      "  [ 8. 37.]\n",
      "  [28.  2.]\n",
      "  [ 0. 35.]\n",
      "  [ 0. 32.]\n",
      "  [ 1. 26.]\n",
      "  [34. 24.]\n",
      "  [35. 39.]\n",
      "  [39.  8.]\n",
      "  [28. 30.]\n",
      "  [26. 31.]\n",
      "  [ 5. 13.]\n",
      "  [45. 31.]\n",
      "  [33. 34.]]\n",
      "\n",
      " [[38. 39.]\n",
      "  [31.  9.]\n",
      "  [24. 21.]\n",
      "  [46. 37.]\n",
      "  [46. 30.]\n",
      "  [ 7. 44.]\n",
      "  [10. 45.]\n",
      "  [19. 25.]\n",
      "  [35. 45.]\n",
      "  [16. 39.]\n",
      "  [37. 17.]\n",
      "  [10.  9.]\n",
      "  [20. 48.]\n",
      "  [45. 17.]\n",
      "  [31. 40.]]\n",
      "\n",
      " [[12. 12.]\n",
      "  [43. 21.]\n",
      "  [11. 15.]\n",
      "  [27. 45.]\n",
      "  [32. 17.]\n",
      "  [ 0.  6.]\n",
      "  [30. 21.]\n",
      "  [39. 42.]\n",
      "  [39. 15.]\n",
      "  [36. 44.]\n",
      "  [19. 13.]\n",
      "  [ 9.  3.]\n",
      "  [12. 45.]\n",
      "  [ 2. 47.]\n",
      "  [49. 15.]]\n",
      "\n",
      " [[16. 15.]\n",
      "  [23. 16.]\n",
      "  [ 0. 20.]\n",
      "  [10. 29.]\n",
      "  [38. 28.]\n",
      "  [15. 37.]\n",
      "  [10. 28.]\n",
      "  [26.  2.]\n",
      "  [40. 29.]\n",
      "  [ 2.  3.]\n",
      "  [ 4. 48.]\n",
      "  [48. 10.]\n",
      "  [ 8. 12.]\n",
      "  [20. 33.]\n",
      "  [28. 31.]]\n",
      "\n",
      " [[44. 38.]\n",
      "  [23. 37.]\n",
      "  [36. 26.]\n",
      "  [ 9.  0.]\n",
      "  [13. 47.]\n",
      "  [10. 34.]\n",
      "  [33. 10.]\n",
      "  [12. 10.]\n",
      "  [11. 43.]\n",
      "  [48. 31.]\n",
      "  [43.  1.]\n",
      "  [40. 42.]\n",
      "  [35. 23.]\n",
      "  [ 6.  0.]\n",
      "  [25. 33.]]]\n",
      "Sequences Y:\n",
      "[[ 43.  27.  74.  47.  21.  53.  70.  59. 102. 107.  76.  28.  75. 110.\n",
      "   64.]\n",
      " [ 29.  37. 109.  67.  66. 103.  71.  85.  70.  62.  40.  56.  75.  47.\n",
      "   86.]\n",
      " [ 23.  31.  76.  38.  63.  32.  27.  59. 108.  82.  97.  85.  44.  81.\n",
      "  112.]\n",
      " [ 38.  31.  76. 107. 122.  97.  62.  54.  99.  90.  70.  56.  78.  82.\n",
      "  116.]\n",
      " [ 12.  43.  69.  83.  76.  38.  51. 111.  93. 119.  68.  31.  66.  61.\n",
      "   66.]\n",
      " [ 16.  23.  43.  39.  76.  90.  53.  38.  95.  45.  54.  62.  68.  61.\n",
      "   79.]\n",
      " [ 44.  23.  85.  45.  69.  57.  53.  55.  66.  90.  92. 125.  98.  41.\n",
      "   64.]]\n"
     ]
    }
   ],
   "source": [
    "num_seqs=7\n",
    "seq_len=15\n",
    "seqs_x=np.array([]).reshape(-1,seq_len,2)\n",
    "seqs_y=np.array([]).reshape(-1,seq_len)\n",
    "for i in xrange(num_seqs):\n",
    "    x0=np.empty((0),dtype=np.float64)\n",
    "    x1=np.empty((0),dtype=np.float64)    \n",
    "    for j in xrange(seq_len):\n",
    "        x0=np.append(x0,np.float64(np.random.randint(0,50)))\n",
    "        x1=np.append(x1,np.float64(np.random.randint(0,50)))\n",
    "\n",
    "    y=np.empty_like(x0)\n",
    "    y[0]=x0[0]\n",
    "    y[1]=x0[1]\n",
    "    for j in xrange(2,seq_len):\n",
    "        y[j]=x0[j]+x0[j-1]+x1[j]\n",
    "    x_vec=np.concatenate((np.reshape(x0,(1,-1,1)),np.reshape(x1,(1,-1,1))),axis=2)\n",
    "    seqs_x=np.concatenate((seqs_x, x_vec ),axis=0)\n",
    "    seqs_y=np.concatenate((seqs_y, np.reshape(y,(1,-1))))\n",
    "    \n",
    "    \n",
    "\n",
    "print \"Sequences X:\"\n",
    "print seqs_x\n",
    "print \"Sequences Y:\"\n",
    "print seqs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "th = np.int(num_seqs*0.7)\n",
    "train_x= seqs_x[:th]\n",
    "test_x = seqs_x[th:]\n",
    "train_y= seqs_y[:th]\n",
    "test_y = seqs_y[th:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 10\n",
    "num_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "num_features=2\n",
    "\n",
    "#The input data is going to be [batch_size]\n",
    "x_data = tf.placeholder(tf.float32, [None, num_features],\"x_data\")\n",
    "\n",
    "#The output data is going to be [batch_size, 1]\n",
    "y_real = tf.placeholder(tf.float32, [None, 1],\"y_real\")\n",
    "\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "\n",
    "\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(x_data, init_state)\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "gvs = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# We save the graph to analyze it in Tensorboard\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le'ts try with an example, yust one sample from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "-0.2244373\n",
      "But it should be:\n",
      "28.0\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "o = sess.run([out], feed_dict={x_data: train_x[0:1,0], \n",
    "                                      y_real:train_y[0:1,0].reshape(-1,1),\n",
    "                                      c_in:np_c, h_in:np_h})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.882385\n",
      "86.09121\n",
      "162.65552\n",
      "145.52869\n",
      "136.37135\n",
      "115.608345\n",
      "95.841606\n",
      "80.55209\n",
      "72.08536\n",
      "45.366634\n",
      "59.180256\n",
      "37.831577\n",
      "24.193466\n",
      "98.015366\n",
      "26.17407\n",
      "26.645082\n",
      "13.29495\n",
      "3.6439674\n",
      "8.933705\n",
      "8.963353\n"
     ]
    }
   ],
   "source": [
    "max_epocs=10000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(train_x.shape[1]):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={x_data: train_x[:,i], \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%500 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[1,1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output sequence is:\n",
      "[22.26746559 64.88938904 64.10012817 58.24990845]\n",
      "The real output sequence is:\n",
      "[21. 34. 96. 53.]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "seq_id=0\n",
    "\n",
    "out_seq=np.array([])\n",
    "for i in xrange(test_x.shape[1]):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={x_data: test_x[seq_id,i].reshape(1,2),       \n",
    "                                                             c_in:np_c, h_in:np_h})\n",
    "    out_seq = np.append(out_seq,out_val)\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "\n",
    "print \"The estimated output sequence is:\"\n",
    "print out_seq\n",
    "print \"The real output sequence is:\"\n",
    "print test_y[seq_id,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train more than one timestep at a time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "lstm_size = 10\n",
    "num_features=2\n",
    "\n",
    "#The input data is going to be [batch_size, max_time, num_features]\n",
    "x_data = tf.placeholder(tf.float32, [None, None, num_features],\"x_data\")\n",
    "\n",
    "#The output data is going to be [batch_size, max_time, 1]\n",
    "y_real = tf.placeholder(tf.float32, [None, None],\"y_real\")\n",
    "\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "\n",
    "batch_size=tf.shape(x_data)[0]\n",
    "init_state = lstm.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# input data shape: \n",
    "output_rnn, out_state = tf.nn.dynamic_rnn(lstm, x_data, initial_state=init_state, dtype=tf.float32)\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "W_repeated = tf.tile(tf.expand_dims(W_out,0), [batch_size,1,1])\n",
    "out = tf.matmul(output_rnn, W_repeated)+b_out\n",
    "out = tf.squeeze(out)\n",
    "\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "gvs = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# We save the graph to analyze it in Tensorboard\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "[[-0.41303676 -0.40426612  0.23558635  1.2864469  -0.49936056 -0.5561915\n",
      "  -0.57699656 -0.24846026 -0.3849225  -0.4438967  -0.4035074   1.0339581\n",
      "  -0.44398555 -0.44611365 -0.2453152 ]\n",
      " [-0.52652174 -0.5018935  -0.4436766  -0.5889065  -0.34171748 -0.55375427\n",
      "  -0.45488316 -0.3766882   0.0370422  -0.5829426  -0.56840324 -0.5856973\n",
      "  -0.31232265 -0.20764083 -0.29059073]\n",
      " [ 0.0423305  -0.49548733 -0.57986057  0.29740518 -0.5950342  -0.59829366\n",
      "  -0.5969884  -0.14465186 -0.27189603 -0.23082167 -0.45416546 -0.51093805\n",
      "  -0.48353654 -0.38957202 -0.43532014]\n",
      " [-0.4363392  -0.2647047  -0.44771308 -0.4104626  -0.39052504 -0.5729186\n",
      "  -0.5752999  -0.11805862 -0.09740436 -0.5325658  -0.34641188 -0.24376509\n",
      "  -0.56210905 -0.361282   -0.47438204]]\n",
      "But it should be:\n",
      "[[ 43.  27.  74.  47.  21.  53.  70.  59. 102. 107.  76.  28.  75. 110.\n",
      "   64.]\n",
      " [ 29.  37. 109.  67.  66. 103.  71.  85.  70.  62.  40.  56.  75.  47.\n",
      "   86.]\n",
      " [ 23.  31.  76.  38.  63.  32.  27.  59. 108.  82.  97.  85.  44.  81.\n",
      "  112.]\n",
      " [ 38.  31.  76. 107. 122.  97.  62.  54.  99.  90.  70.  56.  78.  82.\n",
      "  116.]]\n"
     ]
    }
   ],
   "source": [
    "o = sess.run([out], feed_dict={x_data: train_x, \n",
    "                                      y_real:train_y})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.05057\n",
      "77.25895\n",
      "70.48092\n",
      "61.389854\n",
      "54.191578\n",
      "47.96619\n",
      "42.475643\n",
      "37.183155\n",
      "33.295925\n",
      "30.53872\n",
      "28.356226\n",
      "26.580332\n",
      "25.021322\n",
      "23.525457\n",
      "21.861723\n",
      "18.551582\n",
      "9.578389\n",
      "7.716349\n",
      "6.204856\n",
      "5.0935464\n"
     ]
    }
   ],
   "source": [
    "max_epocs=80000\n",
    "for j in xrange(max_epocs):\n",
    "    myloss,_ = sess.run([loss,train_op], \n",
    "               feed_dict={x_data: train_x, \n",
    "                          y_real:train_y})     \n",
    "    if j%2000 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "[[ 28.157497  24.816872  97.85834  103.21746   72.35114   36.783173\n",
      "   38.754852  60.181187  98.09556  110.00153   72.358116  39.98977\n",
      "   71.943886  57.214634  68.17764 ]\n",
      " [ 31.37629   14.589729  57.650955  51.52385   83.423805  99.51031\n",
      "   57.50415   36.90095   87.96876   44.491516  64.98362   52.612328\n",
      "   56.011658  53.9407    74.93728 ]\n",
      " [ 46.861237  28.572872  96.64514   38.53342   66.94159   50.173164\n",
      "   49.522614  45.25449   65.305405  88.7134    87.1785   108.53193\n",
      "  100.234795  33.81314   79.44018 ]]\n",
      "But it should be:\n",
      "[[ 43.  27.  74.  47.  21.  53.  70.  59. 102. 107.  76.  28.  75. 110.\n",
      "   64.]\n",
      " [ 29.  37. 109.  67.  66. 103.  71.  85.  70.  62.  40.  56.  75.  47.\n",
      "   86.]\n",
      " [ 23.  31.  76.  38.  63.  32.  27.  59. 108.  82.  97.  85.  44.  81.\n",
      "  112.]\n",
      " [ 38.  31.  76. 107. 122.  97.  62.  54.  99.  90.  70.  56.  78.  82.\n",
      "  116.]]\n"
     ]
    }
   ],
   "source": [
    "o = sess.run([out], feed_dict={x_data: test_x, \n",
    "                                      y_real:test_y})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several layers and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "lstm_size1 = 30\n",
    "lstm_size2 = 5\n",
    "drop_out=0.1\n",
    "num_features=2\n",
    "\n",
    "#The input data is going to be [batch_size, max_time, num_features]\n",
    "x_data = tf.placeholder(tf.float32, [None, None, num_features],\"x_data\")\n",
    "#The output data is going to be [batch_size, max_time, 1]\n",
    "y_real = tf.placeholder(tf.float32, [None, None],\"y_real\")\n",
    "\n",
    "lstm_layer1 = tf.contrib.rnn.BasicLSTMCell(lstm_size1, state_is_tuple=True,name=\"LSTM_layer1\")\n",
    "lstm_layer1 = tf.nn.rnn_cell.DropoutWrapper(lstm_layer1, input_keep_prob=drop_out)\n",
    "lstm_layer2 = tf.contrib.rnn.BasicLSTMCell(lstm_size2, state_is_tuple=True,name=\"LSTM_layer2\")\n",
    "lstm_layer2 = tf.nn.rnn_cell.DropoutWrapper(lstm_layer2, input_keep_prob=drop_out)\n",
    "\n",
    "lstm = tf.nn.rnn_cell.MultiRNNCell([lstm_layer1,lstm_layer2], state_is_tuple=True)\n",
    "\n",
    "batch_size=tf.shape(x_data)[0]\n",
    "init_state = lstm.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# input data shape: \n",
    "output_rnn, out_state = tf.nn.dynamic_rnn(lstm, x_data, initial_state=init_state, dtype=tf.float32)\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size2,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "W_repeated = tf.tile(tf.expand_dims(W_out,0), [batch_size,1,1])\n",
    "out = tf.matmul(output_rnn, W_repeated)+b_out\n",
    "out = tf.squeeze(out)\n",
    "\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "gvs = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter ('./tb/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('./tb/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "[[-0.130519   -0.130519   -0.130519   -0.130519   -0.130519   -0.130519\n",
      "  -0.130519   -0.130519   -0.130519   -1.5461134  -0.5214882  -0.2466977\n",
      "  -0.25798646 -0.37975407  0.36350232]\n",
      " [-0.130519   -0.130519   -0.130519   -0.130519   -0.130519   -0.130519\n",
      "  -0.130519   -0.130519   -0.130519   -0.130519   -0.130519   -0.130519\n",
      "  -0.130519   -0.130519   -0.130519  ]\n",
      " [-0.130519   -0.130519   -0.99822617 -0.91869736 -1.2863333  -0.939237\n",
      "  -0.9582306  -0.04468045 -0.3773907  -0.03603727  0.06230752  0.02335078\n",
      "  -0.05038876  0.007392    0.08311416]\n",
      " [-0.130519   -0.130519   -0.130519   -0.130519   -0.130519   -0.130519\n",
      "  -0.130519   -0.25780064 -0.46879348 -0.8717269  -0.94313014 -1.142331\n",
      "  -0.7179986  -2.4164078  -1.0819685 ]]\n",
      "But it should be:\n",
      "[[ 43.  27.  74.  47.  21.  53.  70.  59. 102. 107.  76.  28.  75. 110.\n",
      "   64.]\n",
      " [ 29.  37. 109.  67.  66. 103.  71.  85.  70.  62.  40.  56.  75.  47.\n",
      "   86.]\n",
      " [ 23.  31.  76.  38.  63.  32.  27.  59. 108.  82.  97.  85.  44.  81.\n",
      "  112.]\n",
      " [ 38.  31.  76. 107. 122.  97.  62.  54.  99.  90.  70.  56.  78.  82.\n",
      "  116.]]\n"
     ]
    }
   ],
   "source": [
    "o = sess.run([out], feed_dict={x_data: train_x, \n",
    "                                      y_real:train_y})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4778.294\n",
      "4405.5664\n",
      "4159.7725\n",
      "4081.4028\n",
      "3994.9119\n",
      "3925.9688\n",
      "3850.725\n",
      "3785.6375\n",
      "3713.281\n",
      "3648.4714\n",
      "3581.3223\n",
      "3517.306\n",
      "3455.0757\n",
      "3391.6135\n",
      "3330.9795\n",
      "3266.9792\n",
      "3205.8545\n",
      "3145.659\n",
      "3087.3726\n",
      "3027.4517\n",
      "2969.2905\n",
      "2913.0447\n",
      "2855.6987\n",
      "2799.8145\n",
      "2749.921\n",
      "2690.305\n",
      "2636.469\n",
      "2583.4084\n",
      "2531.5615\n",
      "2479.995\n",
      "2428.6833\n",
      "2378.439\n",
      "2328.9639\n",
      "2280.158\n",
      "2232.058\n",
      "2184.6362\n",
      "2138.1343\n",
      "2091.4287\n",
      "2046.6321\n",
      "2002.0768\n",
      "1958.2598\n",
      "1915.0071\n",
      "1872.5153\n",
      "1830.7249\n",
      "1789.6393\n",
      "1749.208\n",
      "1709.5464\n",
      "1670.5476\n",
      "1632.2944\n",
      "1595.666\n",
      "1557.7493\n",
      "1521.5477\n",
      "1486.0449\n",
      "1451.2441\n",
      "1417.142\n",
      "1383.7499\n",
      "1351.0349\n",
      "1319.0277\n",
      "1287.7196\n",
      "1257.108\n",
      "1227.1941\n",
      "1199.0469\n",
      "1169.4629\n",
      "1141.6438\n",
      "1114.5244\n",
      "1088.1017\n",
      "1062.3389\n",
      "1037.3096\n",
      "1013.0031\n",
      "989.322\n",
      "966.38446\n",
      "941.85156\n",
      "922.56976\n",
      "901.712\n",
      "881.5526\n",
      "862.12866\n",
      "843.3357\n",
      "825.27655\n",
      "807.85443\n",
      "775.904\n",
      "775.2696\n",
      "760.0041\n",
      "745.3347\n",
      "727.0732\n",
      "718.3506\n",
      "705.8587\n",
      "690.3069\n",
      "682.9435\n",
      "672.5339\n",
      "663.0564\n",
      "654.102\n",
      "645.4724\n",
      "653.25366\n",
      "627.6974\n",
      "625.2454\n",
      "619.7798\n",
      "615.0358\n",
      "610.9784\n",
      "589.28644\n",
      "604.93835\n",
      "588.24365\n",
      "602.9716\n",
      "601.25104\n",
      "553.0942\n",
      "585.22125\n",
      "603.77673\n",
      "604.2296\n",
      "606.0628\n",
      "612.171\n",
      "616.9597\n",
      "621.04156\n",
      "587.4839\n",
      "571.48987\n",
      "573.2125\n",
      "603.64825\n",
      "633.19946\n",
      "631.32935\n",
      "633.3617\n",
      "545.017\n",
      "631.7123\n",
      "632.7645\n",
      "616.392\n",
      "632.924\n",
      "617.35626\n",
      "621.92316\n",
      "621.8668\n",
      "633.82745\n",
      "634.21326\n",
      "624.35016\n",
      "609.0335\n",
      "611.54675\n",
      "627.03107\n",
      "621.9778\n",
      "578.6139\n",
      "545.48456\n",
      "583.06757\n",
      "564.5192\n",
      "606.8386\n",
      "550.4324\n",
      "631.24976\n",
      "606.8513\n",
      "566.1787\n",
      "614.3242\n",
      "608.1957\n",
      "588.78625\n",
      "599.0485\n",
      "574.4321\n",
      "621.2044\n",
      "583.47577\n",
      "537.8432\n",
      "563.9633\n",
      "507.17474\n",
      "564.89404\n",
      "484.75223\n",
      "533.5747\n",
      "514.5416\n",
      "519.8471\n",
      "541.96277\n",
      "575.086\n",
      "490.1424\n"
     ]
    }
   ],
   "source": [
    "max_epocs=80000\n",
    "for i in xrange(max_epocs):\n",
    "    myloss,summary,_ = sess.run([loss,merged,train_op], \n",
    "               feed_dict={x_data: train_x, y_real:train_y})  \n",
    "\n",
    "    if i%500 == 0:        \n",
    "        train_writer.add_summary(summary, i)\n",
    "        myloss,summary = sess.run([loss,merged], \n",
    "               feed_dict={x_data: test_x, y_real:test_y})\n",
    "        test_writer.add_summary(summary, i)\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "[[33.481018 52.63614  68.95719  73.23729  73.48899  74.05496  74.23234\n",
      "  74.25668  74.2544   74.27411  74.284355 74.285095 74.28507  74.28501\n",
      "  74.28517 ]\n",
      " [21.609846 48.243286 69.012535 71.15938  73.76045  73.774704 74.12818\n",
      "  74.19079  74.25257  74.253136 74.25452  74.258896 74.25892  74.26134\n",
      "  74.27659 ]\n",
      " [31.201553 57.321785 60.84645  71.67826  71.98312  73.39107  73.537544\n",
      "  74.07591  74.24061  74.267075 74.28226  74.28444  74.28578  74.28595\n",
      "  74.28598 ]]\n",
      "But it should be:\n",
      "[[ 43.  27.  74.  47.  21.  53.  70.  59. 102. 107.  76.  28.  75. 110.\n",
      "   64.]\n",
      " [ 29.  37. 109.  67.  66. 103.  71.  85.  70.  62.  40.  56.  75.  47.\n",
      "   86.]\n",
      " [ 23.  31.  76.  38.  63.  32.  27.  59. 108.  82.  97.  85.  44.  81.\n",
      "  112.]\n",
      " [ 38.  31.  76. 107. 122.  97.  62.  54.  99.  90.  70.  56.  78.  82.\n",
      "  116.]]\n"
     ]
    }
   ],
   "source": [
    "o = sess.run([out], feed_dict={x_data: test_x, \n",
    "                                      y_real:test_y})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.array([[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]]])\n",
    "\n",
    "train_x = np.array([[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]],\n",
    "          [[2], [3], [7], [8]]])\n",
    "\n",
    "train_y = np.array([[1, 3, 7, 11],\n",
    "           [5, 12, 14, 15],\n",
    "           [3, 7, 9, 12],\n",
    "           [2, 5, 10 ,15]])\n",
    "\n",
    "test_x = np.array([[[1], [2], [3], [4]],\n",
    "          [[4], [5], [6], [7]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_steps = 4\n",
    "num_features = 1\n",
    "lstm_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.950649  ],\n",
      "       [-0.6088793 ],\n",
      "       [-0.75499594],\n",
      "       [-0.84744596]], dtype=float32), 14.368125, None]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "batch_step = tf.placeholder(tf.float32, [None, num_features],\"x_train\")\n",
    "y_real = tf.placeholder(tf.float32, [None, num_features])\n",
    "\n",
    "batch_size = tf.shape(batch_step)[0]\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "# Initial state of the LSTM memory.\n",
    "#init_state = state = lstm.zero_state(batch_size,tf.float32)\n",
    "#c_in=tf.zeros((batch_size, lstm_size), np.float32,name=\"c_in\")\n",
    "#h_in=tf.zeros((batch_size, lstm_size),np.float32,name=\"h_in\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "#reset_state=tf.identity_n(init_state)\n",
    "\n",
    "\n",
    "loss = 0.0\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(batch_step, init_state)\n",
    "\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "\n",
    "print sess.run([out,loss,train_op], \n",
    "               feed_dict={batch_step: train_x[:,0,:], \n",
    "                          y_real:train_y[:,0].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49185872\n",
      "0.40784678\n",
      "0.34643236\n",
      "0.30182305\n",
      "0.27053022\n",
      "0.24956086\n",
      "0.23522538\n",
      "0.2237002\n",
      "0.21229109\n",
      "0.19987653\n"
     ]
    }
   ],
   "source": [
    "max_epocs=1000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(4):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={batch_step: train_x[:,i,:], \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%100 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9709455]\n",
      " [4.0639324]]\n",
      "[[2.9082494]\n",
      " [9.049345 ]]\n",
      "[[ 4.6729946]\n",
      " [11.843623 ]]\n",
      "[[ 6.1187854]\n",
      " [12.876646 ]]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((test_x.shape[0], lstm_size),np.float32)\n",
    "np_h = np.zeros((test_x.shape[0], lstm_size),np.float32)\n",
    "\n",
    "for i in xrange(4):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={batch_step: test_x[:,i,:],c_in:np_c, h_in:np_h})\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "    print out_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]],\n",
       "\n",
       "       [[4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7]]])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[ 1.6971655  2.9445994  4.9434905  7.257107 ]\n",
    " [ 4.436798   9.061197  11.678692  12.575489 ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeriesPredictor:\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.seq_size=seq_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.W_out = tf.Variable(tf.random_normal([hidden_dim,1]),name='W_out')\n",
    "        self.b_out = tf.Variable(tf.random_normal([1]),name='b_out')\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "        \n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.square(self.model()-self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        :param x: inputs of size [T, batch_size, input_size]\n",
    "        :param W: matrix of fully-connected output layer weights\n",
    "        :param b: vector of fully-connected output layer biases\n",
    "        \"\"\"\n",
    "        cell = rnn.BasicLSTMCell(self.hidden_dim)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out,0), [num_examples,1,1])\n",
    "        out = tf.matmul(outputs, W_repeated)+self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "    \n",
    "    def train(self, train_x, train_y):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(1000):\n",
    "                _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "                if i% 100 == 0:\n",
    "                    print(i,mse)\n",
    "            save_path = self.saver.save(sess,'./model.ckpt')\n",
    "            print('Model saved to {}'.format(save_path))\n",
    "                \n",
    "        \n",
    "    def test(self,test_x):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            self.saver.restore(sess, './model.ckpt')\n",
    "            output = sess.run(self.model(), feed_dict={self.x: test_x})\n",
    "            print(output)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeriesPredictor:\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.seq_size=seq_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([hidden_dim,1]))\n",
    "        self.b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "        \n",
    "        self.mymodel = self.model()\n",
    "        self.cost = tf.reduce_mean(tf.square(self.mymodel-self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        :param x: inputs of size [T, batch_size, input_size]\n",
    "        :param W: matrix of fully-connected output layer weights\n",
    "        :param b: vector of fully-connected output layer biases\n",
    "        \"\"\"\n",
    "        cell = rnn.BasicLSTMCell(self.hidden_dim)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out,0), [num_examples,1,1])\n",
    "        out = tf.matmul(outputs, W_repeated)+self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "    \n",
    "    def train(self, train_x, train_y):\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(1000):\n",
    "            _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "            if i% 100 == 0:\n",
    "                print(i,mse)\n",
    "        return sess\n",
    "                \n",
    "        \n",
    "    def test(self,sess,test_x):        \n",
    "        output = sess.run(self.mymodel, feed_dict={self.x: test_x})\n",
    "        print(output)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 104.54908)\n",
      "(100, 49.596928)\n",
      "(200, 13.441304)\n",
      "(300, 4.84034)\n",
      "(400, 3.223334)\n",
      "(500, 2.582983)\n",
      "(600, 1.9891154)\n",
      "(700, 1.4041783)\n",
      "(800, 1.0117636)\n",
      "(900, 0.73919386)\n",
      "[[ 0.69609344  2.6687462   5.052478    6.9160995 ]\n",
      " [ 4.0849714   9.2390785  11.849617   12.85392   ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "predictor = SeriesPredictor(input_dim=1, seq_size=4, hidden_dim=10)\n",
    "train_x = [[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]]]\n",
    "train_y = [[1, 3, 7, 11],\n",
    "           [5, 12, 14, 15],\n",
    "           [3, 7, 9, 12]]\n",
    "sess=predictor.train(train_x, train_y)\n",
    "\n",
    "test_x = [[[1], [2], [3], [4]],\n",
    "          [[4], [5], [6], [7]]]\n",
    "\n",
    "predictor.test(sess,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2], [5], [6]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
