{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start creating a series for training.\n",
    "\n",
    "y[0] = x[0]\n",
    "\n",
    "y[1] = x[1]\n",
    "\n",
    "y[2] = x[0]+x[1]\n",
    "\n",
    "\n",
    "We are going to create different trainning sequences with different startup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences X:\n",
      "[[ 3.  6.  2. 49. 24.  8. 40.  6. 28. 46. 33. 46. 30. 36. 24.  7. 10. 17.\n",
      "   9.  2.  5. 39. 36. 37. 33. 29. 10. 33. 42. 42.]\n",
      " [43.  5. 28. 12. 35. 27. 27. 27.  0. 11. 12. 26. 36. 35. 34. 11. 40. 49.\n",
      "   0. 39. 23.  9.  2. 37. 39. 38.  9.  1. 28. 22.]\n",
      " [17. 21. 38. 15.  1. 20. 12. 15. 19. 48. 43. 38. 41. 49. 21.  2. 12. 44.\n",
      "  40. 27.  9. 32. 49. 16. 49. 36. 27. 26. 15. 38.]\n",
      " [49. 33. 47. 19. 35. 38. 21. 42.  9. 33. 17. 35. 11.  7. 34. 35. 32.  2.\n",
      "  11. 23. 32. 30. 14. 31. 39. 23. 32. 46. 47. 29.]\n",
      " [ 0. 21. 21. 21. 32. 16. 48. 28. 20. 28. 23. 22. 41.  7. 37.  3. 44. 49.\n",
      "  14. 12. 43. 19. 23. 12. 49. 16. 31. 11. 38. 10.]\n",
      " [ 8. 24. 31. 46. 48. 10. 43.  3.  4. 13. 49.  1. 35. 24. 40. 20.  0. 24.\n",
      "  48. 47.  0. 17. 11. 33. 30. 16. 41. 11. 39. 23.]\n",
      " [28. 15. 17.  4. 40. 28. 34. 39. 18. 47. 23. 33. 32. 46. 19. 44. 28. 35.\n",
      "  33. 17. 34. 36. 42. 47. 41.  6. 29. 16.  4. 38.]]\n",
      "Sequences Y:\n",
      "[[ 3.  6.  8. 51. 73. 32. 48. 46. 34. 74. 79. 79. 76. 66. 60. 31. 17. 27.\n",
      "  26. 11.  7. 44. 75. 73. 70. 62. 39. 43. 75. 84.]\n",
      " [43.  5. 33. 40. 47. 62. 54. 54. 27. 11. 23. 38. 62. 71. 69. 45. 51. 89.\n",
      "  49. 39. 62. 32. 11. 39. 76. 77. 47. 10. 29. 50.]\n",
      " [17. 21. 59. 53. 16. 21. 32. 27. 34. 67. 91. 81. 79. 90. 70. 23. 14. 56.\n",
      "  84. 67. 36. 41. 81. 65. 65. 85. 63. 53. 41. 53.]\n",
      " [49. 33. 80. 66. 54. 73. 59. 63. 51. 42. 50. 52. 46. 18. 41. 69. 67. 34.\n",
      "  13. 34. 55. 62. 44. 45. 70. 62. 55. 78. 93. 76.]\n",
      " [ 0. 21. 42. 42. 53. 48. 64. 76. 48. 48. 51. 45. 63. 48. 44. 40. 47. 93.\n",
      "  63. 26. 55. 62. 42. 35. 61. 65. 47. 42. 49. 48.]\n",
      " [ 8. 24. 55. 77. 94. 58. 53. 46.  7. 17. 62. 50. 36. 59. 64. 60. 20. 24.\n",
      "  72. 95. 47. 17. 28. 44. 63. 46. 57. 52. 50. 62.]\n",
      " [28. 15. 32. 21. 44. 68. 62. 73. 57. 65. 70. 56. 65. 78. 65. 63. 72. 63.\n",
      "  68. 50. 51. 70. 78. 89. 88. 47. 35. 45. 20. 42.]]\n"
     ]
    }
   ],
   "source": [
    "num_seqs=7\n",
    "seq_len=30\n",
    "seqs_x=np.array([]).reshape(-1,seq_len)\n",
    "seqs_y=np.array([]).reshape(-1,seq_len)\n",
    "for i in xrange(num_seqs):\n",
    "    x=np.empty((0),dtype=np.float64)\n",
    "    for j in xrange(seq_len):\n",
    "        x=np.append(x,np.float64(np.random.randint(0,50)))\n",
    "\n",
    "    y=np.empty_like(x)\n",
    "    y[0]=x[0]\n",
    "    y[1]=x[1]\n",
    "    for j in xrange(2,len(x)):\n",
    "        y[j]=x[j]+x[j-1]\n",
    "    seqs_x=np.concatenate((seqs_x, np.reshape(x,(1,-1))))\n",
    "    seqs_y=np.concatenate((seqs_y, np.reshape(y,(1,-1))))\n",
    "    \n",
    "    \n",
    "\n",
    "print \"Sequences X:\"\n",
    "print seqs_x\n",
    "print \"Sequences Y:\"\n",
    "print seqs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.int(num_seqs*0.7)\n",
    "train_x= seqs_x[:th]\n",
    "test_x = seqs_x[th:]\n",
    "train_y= seqs_y[:th]\n",
    "test_y = seqs_y[th:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 10\n",
    "num_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#The input data is going to be [batch_size]\n",
    "x_data = tf.placeholder(tf.float32, [None, 1],\"x_data\")\n",
    "\n",
    "#The output data is going to be [batch_size, 1]\n",
    "y_real = tf.placeholder(tf.float32, [None, 1],\"y_real\")\n",
    "\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "\n",
    "\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(x_data, init_state)\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "gvs = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# We save the graph to analyze it in Tensorboard\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le'ts try with an example, yust one sample from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "0.17150217\n",
      "But it should be:\n",
      "43.0\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "o = sess.run([out], feed_dict={x_data: train_x[0:1,0].reshape(-1,1), \n",
    "                                      y_real:train_y[0:1,0].reshape(-1,1),\n",
    "                                      c_in:np_c, h_in:np_h})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4417.588\n",
      "912.04236\n",
      "222.94768\n",
      "125.8858\n",
      "57.600925\n",
      "50.0817\n",
      "74.85818\n",
      "28.053059\n",
      "7.297879\n",
      "21.0089\n",
      "8.8673115\n",
      "13.872299\n",
      "23.86504\n",
      "2.0798922\n",
      "2.675952\n",
      "25.015575\n",
      "6.814285\n",
      "83.88816\n",
      "39.195007\n",
      "15.484887\n"
     ]
    }
   ],
   "source": [
    "max_epocs=10000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(train_x.shape[1]):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={x_data: train_x[:,i].reshape(-1,1), \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%500 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check with the known sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output sequence is:\n",
      "[12.32107353 22.30460358 43.58792496 42.40033722 61.8417778  53.01939011\n",
      " 56.33670044 58.39256287 45.43508148 56.55605316 54.44507599 44.94801712\n",
      " 69.1426239  39.26014709 48.01186752 23.61235046 35.5365715  70.59922028\n",
      " 53.08533478 25.87182236 52.11916351 55.65919113 37.14069748 41.71841049\n",
      " 51.17979431 57.79838562 43.18199921 46.7674408  47.27316666 51.6287117 ]\n",
      "The real output sequence is:\n",
      "[ 0. 21. 42. 42. 53. 48. 64. 76. 48. 48. 51. 45. 63. 48. 44. 40. 47. 93.\n",
      " 63. 26. 55. 62. 42. 35. 61. 65. 47. 42. 49. 48.]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "seq_id=0\n",
    "\n",
    "out_seq=np.array([])\n",
    "for i in xrange(test_x.shape[1]):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={x_data: test_x[seq_id,i].reshape(-1,1),       \n",
    "                                                             c_in:np_c, h_in:np_h})\n",
    "    out_seq = np.append(out_seq,out_val)\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "\n",
    "print \"The estimated output sequence is:\"\n",
    "print out_seq\n",
    "print \"The real output sequence is:\"\n",
    "print test_y[seq_id,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences with N-dimensions\n",
    "\n",
    "We are going to start creating a series for training.\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "  y[0] &= x_0[0] \\\\\n",
    "  y[1] &= x_0[1] \\\\\n",
    "  y[2] &= x_0[0]+x_0[1]+x_1[2]+x_1[1]    \n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences X:\n",
      "[[[20. 17.]\n",
      "  [ 2. 47.]\n",
      "  [22. 15.]\n",
      "  [38. 12.]]\n",
      "\n",
      " [[28. 38.]\n",
      "  [32. 24.]\n",
      "  [27. 19.]\n",
      "  [14.  1.]]\n",
      "\n",
      " [[49.  3.]\n",
      "  [39.  8.]\n",
      "  [41. 13.]\n",
      "  [ 9.  8.]]\n",
      "\n",
      " [[34. 10.]\n",
      "  [27.  6.]\n",
      "  [ 3. 35.]\n",
      "  [23. 24.]]\n",
      "\n",
      " [[21. 26.]\n",
      "  [34.  0.]\n",
      "  [20. 42.]\n",
      "  [13. 20.]]\n",
      "\n",
      " [[49. 33.]\n",
      "  [ 7. 20.]\n",
      "  [22.  4.]\n",
      "  [41. 46.]]\n",
      "\n",
      " [[ 8. 49.]\n",
      "  [32.  4.]\n",
      "  [20.  2.]\n",
      "  [37. 37.]]]\n",
      "Sequences Y:\n",
      "[[ 20.   2.  39.  72.]\n",
      " [ 28.  32.  78.  42.]\n",
      " [ 49.  39.  93.  58.]\n",
      " [ 34.  27.  65.  50.]\n",
      " [ 21.  34.  96.  53.]\n",
      " [ 49.   7.  33. 109.]\n",
      " [  8.  32.  54.  94.]]\n"
     ]
    }
   ],
   "source": [
    "num_seqs=7\n",
    "seq_len=4\n",
    "seqs_x=np.array([]).reshape(-1,seq_len,2)\n",
    "seqs_y=np.array([]).reshape(-1,seq_len)\n",
    "for i in xrange(num_seqs):\n",
    "    x0=np.empty((0),dtype=np.float64)\n",
    "    x1=np.empty((0),dtype=np.float64)    \n",
    "    for j in xrange(seq_len):\n",
    "        x0=np.append(x0,np.float64(np.random.randint(0,50)))\n",
    "        x1=np.append(x1,np.float64(np.random.randint(0,50)))\n",
    "\n",
    "    y=np.empty_like(x0)\n",
    "    y[0]=x0[0]\n",
    "    y[1]=x0[1]\n",
    "    for j in xrange(2,seq_len):\n",
    "        y[j]=x0[j]+x0[j-1]+x1[j]\n",
    "    x_vec=np.concatenate((np.reshape(x0,(1,-1,1)),np.reshape(x1,(1,-1,1))),axis=2)\n",
    "    seqs_x=np.concatenate((seqs_x, x_vec ),axis=0)\n",
    "    seqs_y=np.concatenate((seqs_y, np.reshape(y,(1,-1))))\n",
    "    \n",
    "    \n",
    "\n",
    "print \"Sequences X:\"\n",
    "print seqs_x\n",
    "print \"Sequences Y:\"\n",
    "print seqs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.int(num_seqs*0.7)\n",
    "train_x= seqs_x[:th]\n",
    "test_x = seqs_x[th:]\n",
    "train_y= seqs_y[:th]\n",
    "test_y = seqs_y[th:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 10\n",
    "num_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "num_features=2\n",
    "\n",
    "#The input data is going to be [batch_size]\n",
    "x_data = tf.placeholder(tf.float32, [None, num_features],\"x_data\")\n",
    "\n",
    "#The output data is going to be [batch_size, 1]\n",
    "y_real = tf.placeholder(tf.float32, [None, 1],\"y_real\")\n",
    "\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "\n",
    "\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(x_data, init_state)\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "gvs = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# We save the graph to analyze it in Tensorboard\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le'ts try with an example, yust one sample from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "-0.2244373\n",
      "But it should be:\n",
      "28.0\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "o = sess.run([out], feed_dict={x_data: train_x[0:1,0], \n",
    "                                      y_real:train_y[0:1,0].reshape(-1,1),\n",
    "                                      c_in:np_c, h_in:np_h})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.882385\n",
      "86.09121\n",
      "162.65552\n",
      "145.52869\n",
      "136.37135\n",
      "115.608345\n",
      "95.841606\n",
      "80.55209\n",
      "72.08536\n",
      "45.366634\n",
      "59.180256\n",
      "37.831577\n",
      "24.193466\n",
      "98.015366\n",
      "26.17407\n",
      "26.645082\n",
      "13.29495\n",
      "3.6439674\n",
      "8.933705\n",
      "8.963353\n"
     ]
    }
   ],
   "source": [
    "max_epocs=10000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(train_x.shape[1]):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={x_data: train_x[:,i], \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%500 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[1,1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output sequence is:\n",
      "[22.26746559 64.88938904 64.10012817 58.24990845]\n",
      "The real output sequence is:\n",
      "[21. 34. 96. 53.]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "seq_id=0\n",
    "\n",
    "out_seq=np.array([])\n",
    "for i in xrange(test_x.shape[1]):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={x_data: test_x[seq_id,i].reshape(1,2),       \n",
    "                                                             c_in:np_c, h_in:np_h})\n",
    "    out_seq = np.append(out_seq,out_val)\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "\n",
    "print \"The estimated output sequence is:\"\n",
    "print out_seq\n",
    "print \"The real output sequence is:\"\n",
    "print test_y[seq_id,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train more than one timestep at a time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29., 44., 73., 74., 47., 45., 29., 40., 48., 52., 90., 52., 42.,\n",
       "       84., 92.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[seq_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array([[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]]])\n",
    "\n",
    "train_x = np.array([[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]],\n",
    "          [[2], [3], [7], [8]]])\n",
    "\n",
    "train_y = np.array([[1, 3, 7, 11],\n",
    "           [5, 12, 14, 15],\n",
    "           [3, 7, 9, 12],\n",
    "           [2, 5, 10 ,15]])\n",
    "\n",
    "test_x = np.array([[[1], [2], [3], [4]],\n",
    "          [[4], [5], [6], [7]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 4\n",
    "num_features = 1\n",
    "lstm_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.950649  ],\n",
      "       [-0.6088793 ],\n",
      "       [-0.75499594],\n",
      "       [-0.84744596]], dtype=float32), 14.368125, None]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "batch_step = tf.placeholder(tf.float32, [None, num_features],\"x_train\")\n",
    "y_real = tf.placeholder(tf.float32, [None, num_features])\n",
    "\n",
    "batch_size = tf.shape(batch_step)[0]\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "# Initial state of the LSTM memory.\n",
    "#init_state = state = lstm.zero_state(batch_size,tf.float32)\n",
    "#c_in=tf.zeros((batch_size, lstm_size), np.float32,name=\"c_in\")\n",
    "#h_in=tf.zeros((batch_size, lstm_size),np.float32,name=\"h_in\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "#reset_state=tf.identity_n(init_state)\n",
    "\n",
    "\n",
    "loss = 0.0\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(batch_step, init_state)\n",
    "\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "\n",
    "print sess.run([out,loss,train_op], \n",
    "               feed_dict={batch_step: train_x[:,0,:], \n",
    "                          y_real:train_y[:,0].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49185872\n",
      "0.40784678\n",
      "0.34643236\n",
      "0.30182305\n",
      "0.27053022\n",
      "0.24956086\n",
      "0.23522538\n",
      "0.2237002\n",
      "0.21229109\n",
      "0.19987653\n"
     ]
    }
   ],
   "source": [
    "max_epocs=1000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(4):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={batch_step: train_x[:,i,:], \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%100 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9709455]\n",
      " [4.0639324]]\n",
      "[[2.9082494]\n",
      " [9.049345 ]]\n",
      "[[ 4.6729946]\n",
      " [11.843623 ]]\n",
      "[[ 6.1187854]\n",
      " [12.876646 ]]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((test_x.shape[0], lstm_size),np.float32)\n",
    "np_h = np.zeros((test_x.shape[0], lstm_size),np.float32)\n",
    "\n",
    "for i in xrange(4):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={batch_step: test_x[:,i,:],c_in:np_c, h_in:np_h})\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "    print out_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]],\n",
       "\n",
       "       [[4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7]]])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[ 1.6971655  2.9445994  4.9434905  7.257107 ]\n",
    " [ 4.436798   9.061197  11.678692  12.575489 ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeriesPredictor:\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.seq_size=seq_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.W_out = tf.Variable(tf.random_normal([hidden_dim,1]),name='W_out')\n",
    "        self.b_out = tf.Variable(tf.random_normal([1]),name='b_out')\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "        \n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.square(self.model()-self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        :param x: inputs of size [T, batch_size, input_size]\n",
    "        :param W: matrix of fully-connected output layer weights\n",
    "        :param b: vector of fully-connected output layer biases\n",
    "        \"\"\"\n",
    "        cell = rnn.BasicLSTMCell(self.hidden_dim)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out,0), [num_examples,1,1])\n",
    "        out = tf.matmul(outputs, W_repeated)+self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "    \n",
    "    def train(self, train_x, train_y):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(1000):\n",
    "                _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "                if i% 100 == 0:\n",
    "                    print(i,mse)\n",
    "            save_path = self.saver.save(sess,'./model.ckpt')\n",
    "            print('Model saved to {}'.format(save_path))\n",
    "                \n",
    "        \n",
    "    def test(self,test_x):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            self.saver.restore(sess, './model.ckpt')\n",
    "            output = sess.run(self.model(), feed_dict={self.x: test_x})\n",
    "            print(output)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeriesPredictor:\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.seq_size=seq_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([hidden_dim,1]))\n",
    "        self.b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "        \n",
    "        self.mymodel = self.model()\n",
    "        self.cost = tf.reduce_mean(tf.square(self.mymodel-self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        :param x: inputs of size [T, batch_size, input_size]\n",
    "        :param W: matrix of fully-connected output layer weights\n",
    "        :param b: vector of fully-connected output layer biases\n",
    "        \"\"\"\n",
    "        cell = rnn.BasicLSTMCell(self.hidden_dim)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out,0), [num_examples,1,1])\n",
    "        out = tf.matmul(outputs, W_repeated)+self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "    \n",
    "    def train(self, train_x, train_y):\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(1000):\n",
    "            _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "            if i% 100 == 0:\n",
    "                print(i,mse)\n",
    "        return sess\n",
    "                \n",
    "        \n",
    "    def test(self,sess,test_x):        \n",
    "        output = sess.run(self.mymodel, feed_dict={self.x: test_x})\n",
    "        print(output)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 104.54908)\n",
      "(100, 49.596928)\n",
      "(200, 13.441304)\n",
      "(300, 4.84034)\n",
      "(400, 3.223334)\n",
      "(500, 2.582983)\n",
      "(600, 1.9891154)\n",
      "(700, 1.4041783)\n",
      "(800, 1.0117636)\n",
      "(900, 0.73919386)\n",
      "[[ 0.69609344  2.6687462   5.052478    6.9160995 ]\n",
      " [ 4.0849714   9.2390785  11.849617   12.85392   ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "predictor = SeriesPredictor(input_dim=1, seq_size=4, hidden_dim=10)\n",
    "train_x = [[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]]]\n",
    "train_y = [[1, 3, 7, 11],\n",
    "           [5, 12, 14, 15],\n",
    "           [3, 7, 9, 12]]\n",
    "sess=predictor.train(train_x, train_y)\n",
    "\n",
    "test_x = [[[1], [2], [3], [4]],\n",
    "          [[4], [5], [6], [7]]]\n",
    "\n",
    "predictor.test(sess,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2], [5], [6]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
