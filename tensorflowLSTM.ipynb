{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start creating a series for training.\n",
    "\n",
    "y[0] = x[0]\n",
    "\n",
    "y[1] = x[1]\n",
    "\n",
    "y[2] = x[0]+x[1]\n",
    "\n",
    "\n",
    "We are going to create different trainning sequences with different startup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences X:\n",
      "[[23. 20. 32. 32.  3. 14. 22. 28.  5. 22.  4. 27. 26. 33. 29.]\n",
      " [ 3. 33.  1. 47. 48. 14. 13. 25.  5. 25. 19. 41. 10. 45. 25.]\n",
      " [24. 11. 13. 30.  7. 13.  7.  2.  0.  1. 19. 38.  6. 31. 12.]\n",
      " [ 0. 23. 49.  8. 33. 28.  0. 46. 10. 38. 29. 15.  8.  2. 19.]\n",
      " [29. 44. 30. 17. 28.  1. 39.  9. 43. 47.  5. 37. 47. 45. 11.]\n",
      " [19. 33. 29. 49.  3. 35. 13. 13. 11. 12. 35. 22. 47. 25. 21.]\n",
      " [47. 14. 25. 40. 21. 19. 29. 41.  3. 27. 34. 31. 46. 48. 43.]]\n",
      "Sequences Y:\n",
      "[[23. 20. 43. 52. 64. 35. 17. 36. 50. 33. 27. 26. 31. 53. 59.]\n",
      " [ 3. 33. 36. 34. 48. 95. 62. 27. 38. 30. 30. 44. 60. 51. 55.]\n",
      " [24. 11. 35. 24. 43. 37. 20. 20.  9.  2.  1. 20. 57. 44. 37.]\n",
      " [ 0. 23. 23. 72. 57. 41. 61. 28. 46. 56. 48. 67. 44. 23. 10.]\n",
      " [29. 44. 73. 74. 47. 45. 29. 40. 48. 52. 90. 52. 42. 84. 92.]\n",
      " [19. 33. 52. 62. 78. 52. 38. 48. 26. 24. 23. 47. 57. 69. 72.]\n",
      " [47. 14. 61. 39. 65. 61. 40. 48. 70. 44. 30. 61. 65. 77. 94.]]\n"
     ]
    }
   ],
   "source": [
    "num_seqs=7\n",
    "seq_len=15\n",
    "seqs_x=np.array([]).reshape(-1,seq_len)\n",
    "seqs_y=np.array([]).reshape(-1,seq_len)\n",
    "for i in xrange(num_seqs):\n",
    "    x=np.empty((0),dtype=np.float64)\n",
    "    for j in xrange(seq_len):\n",
    "        x=np.append(x,np.float64(np.random.randint(0,50)))\n",
    "\n",
    "    y=np.empty_like(x)\n",
    "    y[0]=x[0]\n",
    "    y[1]=x[1]\n",
    "    for j in xrange(2,len(x)):\n",
    "        y[j]=x[j-1]+x[j-2]\n",
    "    seqs_x=np.concatenate((seqs_x, np.reshape(x,(1,-1))))\n",
    "    seqs_y=np.concatenate((seqs_y, np.reshape(y,(1,-1))))\n",
    "    \n",
    "    \n",
    "\n",
    "print \"Sequences X:\"\n",
    "print seqs_x\n",
    "print \"Sequences Y:\"\n",
    "print seqs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "th = np.int(num_seqs*0.7)\n",
    "train_x= seqs_x[:th]\n",
    "test_x = seqs_x[th:]\n",
    "train_y= seqs_y[:th]\n",
    "test_y = seqs_y[th:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 10\n",
    "num_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#The input data is going to be [batch_size]\n",
    "x_data = tf.placeholder(tf.float32, [None, 1],\"x_data\")\n",
    "\n",
    "#The output data is going to be [batch_size, 1]\n",
    "y_real = tf.placeholder(tf.float32, [None, 1],\"y_real\")\n",
    "\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "\n",
    "\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(x_data, init_state)\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# We save the graph to analyze it in Tensorboard\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le'ts try with an example, yust one sample from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output without training is:\n",
      "0.0042195916\n",
      "But it should be:\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "o = sess.run([out], feed_dict={x_data: train_x[0:1,0].reshape(-1,1), \n",
    "                                      y_real:train_y[0:1,0].reshape(-1,1),\n",
    "                                      c_in:np_c, h_in:np_h})\n",
    "\n",
    "print \"The estimated output without training is:\"\n",
    "print np.squeeze(o)\n",
    "print \"But it should be:\"\n",
    "print train_y[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046.0165\n",
      "438.22595\n",
      "373.78998\n",
      "337.576\n",
      "340.35507\n",
      "252.77315\n",
      "175.91467\n",
      "163.68973\n",
      "126.21148\n",
      "125.45929\n",
      "115.56317\n",
      "67.36999\n",
      "48.805077\n",
      "48.48239\n",
      "51.104794\n",
      "16.888826\n",
      "3.3809328\n",
      "29.782288\n",
      "57.244755\n",
      "19.60713\n",
      "59.499363\n",
      "29.204899\n",
      "11.019059\n",
      "8.672547\n",
      "9.082928\n",
      "3.394328\n",
      "1.7342178\n",
      "0.6894849\n",
      "23.618866\n",
      "18.484379\n",
      "31.286089\n",
      "86.694435\n",
      "80.29189\n",
      "9.22579\n",
      "29.815407\n",
      "65.00361\n",
      "7.24303\n",
      "28.543066\n",
      "29.233694\n",
      "107.85974\n",
      "182.72688\n",
      "86.162254\n",
      "213.87238\n",
      "81.63963\n",
      "59.246887\n",
      "13.777568\n",
      "34.940994\n",
      "46.585064\n",
      "22.325748\n",
      "15.47254\n"
     ]
    }
   ],
   "source": [
    "max_epocs=10000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(train_x.shape[1]):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={x_data: train_x[:,i].reshape(-1,1), \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%200 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check with the known sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated output sequence is:\n",
      "[19.21244049 31.39744949 38.73437881 31.38534737 54.78489685 11.93888664\n",
      " 57.93574142 51.94184494 34.24225235 19.72789574 34.66477585 51.43584824\n",
      " 50.71542358 55.28791809 72.36883545]\n",
      "The real output sequence is:\n",
      "[19. 33. 52. 62. 78. 52. 38. 48. 26. 24. 23. 47. 57. 69. 72.]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((1, lstm_size),np.float32)\n",
    "np_h = np.zeros((1, lstm_size),np.float32)\n",
    "\n",
    "seq_id=1\n",
    "\n",
    "out_seq=np.array([])\n",
    "for i in xrange(test_x.shape[1]):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={x_data: test_x[seq_id,i].reshape(-1,1),       \n",
    "                                                             c_in:np_c, h_in:np_h})\n",
    "    out_seq = np.append(out_seq,out_val)\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "\n",
    "print \"The estimated output sequence is:\"\n",
    "print out_seq\n",
    "print \"The real output sequence is:\"\n",
    "print test_y[seq_id,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences with N-dimensions\n",
    "\n",
    "We are going to start creating a series for training.\n",
    "\\\\[\n",
    "  y[0] = x[0]\n",
    "  y[1] = x[1]\n",
    "  y[2] = x[0]+x[1]    \n",
    "\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_seqs=7\n",
    "seq_len=15\n",
    "seqs_x=np.array([]).reshape(-1,seq_len)\n",
    "seqs_y=np.array([]).reshape(-1,seq_len)\n",
    "for i in xrange(num_seqs):\n",
    "    x=np.empty((0),dtype=np.float64)\n",
    "    for j in xrange(seq_len):\n",
    "        x=np.append(x,np.float64(np.random.randint(0,50)))\n",
    "\n",
    "    y=np.empty_like(x)\n",
    "    y[0]=x[0]\n",
    "    y[1]=x[1]\n",
    "    for j in xrange(2,len(x)):\n",
    "        y[j]=x[j-1]+x[j-2]\n",
    "    seqs_x=np.concatenate((seqs_x, np.reshape(x,(1,-1))))\n",
    "    seqs_y=np.concatenate((seqs_y, np.reshape(y,(1,-1))))\n",
    "    \n",
    "    \n",
    "\n",
    "print \"Sequences X:\"\n",
    "print seqs_x\n",
    "print \"Sequences Y:\"\n",
    "print seqs_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29., 44., 73., 74., 47., 45., 29., 40., 48., 52., 90., 52., 42.,\n",
       "       84., 92.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[seq_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = np.array([[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]]])\n",
    "\n",
    "train_x = np.array([[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]],\n",
    "          [[2], [3], [7], [8]]])\n",
    "\n",
    "train_y = np.array([[1, 3, 7, 11],\n",
    "           [5, 12, 14, 15],\n",
    "           [3, 7, 9, 12],\n",
    "           [2, 5, 10 ,15]])\n",
    "\n",
    "test_x = np.array([[[1], [2], [3], [4]],\n",
    "          [[4], [5], [6], [7]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_steps = 4\n",
    "num_features = 1\n",
    "lstm_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.950649  ],\n",
      "       [-0.6088793 ],\n",
      "       [-0.75499594],\n",
      "       [-0.84744596]], dtype=float32), 14.368125, None]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "batch_step = tf.placeholder(tf.float32, [None, num_features],\"x_train\")\n",
    "y_real = tf.placeholder(tf.float32, [None, num_features])\n",
    "\n",
    "batch_size = tf.shape(batch_step)[0]\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, state_is_tuple=True,name=\"LSTM_cell\")\n",
    "# Initial state of the LSTM memory.\n",
    "#init_state = state = lstm.zero_state(batch_size,tf.float32)\n",
    "#c_in=tf.zeros((batch_size, lstm_size), np.float32,name=\"c_in\")\n",
    "#h_in=tf.zeros((batch_size, lstm_size),np.float32,name=\"h_in\")\n",
    "c_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"c_in\")\n",
    "h_in=tf.placeholder(tf.float32, [None, lstm_size],name=\"h_in\")\n",
    "                    \n",
    "init_state = tf.contrib.rnn.LSTMStateTuple( c=c_in, h=h_in)\n",
    "#reset_state=tf.identity_n(init_state)\n",
    "\n",
    "\n",
    "loss = 0.0\n",
    "# The value of state is updated after processing each batch of words.\n",
    "output_rnn, out_state = lstm(batch_step, init_state)\n",
    "\n",
    "\n",
    "W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([lstm_size,1]))\n",
    "b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "\n",
    "\n",
    "# The LSTM output can be used to make next word predictions\n",
    "out = tf.matmul(output_rnn, W_out) + b_out\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_real,out)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "\n",
    "print sess.run([out,loss,train_op], \n",
    "               feed_dict={batch_step: train_x[:,0,:], \n",
    "                          y_real:train_y[:,0].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })\n",
    "train_writer = tf.summary.FileWriter('./graphtf',sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49185872\n",
      "0.40784678\n",
      "0.34643236\n",
      "0.30182305\n",
      "0.27053022\n",
      "0.24956086\n",
      "0.23522538\n",
      "0.2237002\n",
      "0.21229109\n",
      "0.19987653\n"
     ]
    }
   ],
   "source": [
    "max_epocs=1000\n",
    "for j in xrange(max_epocs):\n",
    "    np_c = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    np_h = np.zeros((train_x.shape[0], lstm_size),np.float32)\n",
    "    for i in xrange(4):        \n",
    "        new_state,myloss,_ = sess.run([out_state,loss,train_op], \n",
    "               feed_dict={batch_step: train_x[:,i,:], \n",
    "                          y_real:train_y[:,i].reshape(-1,1),\n",
    "                          c_in:np_c, h_in:np_h\n",
    "                         })        \n",
    "        np_c=new_state.c\n",
    "        np_h=new_state.h\n",
    "    if j%100 == 0:\n",
    "        print myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9709455]\n",
      " [4.0639324]]\n",
      "[[2.9082494]\n",
      " [9.049345 ]]\n",
      "[[ 4.6729946]\n",
      " [11.843623 ]]\n",
      "[[ 6.1187854]\n",
      " [12.876646 ]]\n"
     ]
    }
   ],
   "source": [
    "np_c = np.zeros((test_x.shape[0], lstm_size),np.float32)\n",
    "np_h = np.zeros((test_x.shape[0], lstm_size),np.float32)\n",
    "\n",
    "for i in xrange(4):\n",
    "    out_val,new_state = sess.run([out,out_state], feed_dict={batch_step: test_x[:,i,:],c_in:np_c, h_in:np_h})\n",
    "    np_c=new_state.c\n",
    "    np_h=new_state.h\n",
    "    print out_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]],\n",
       "\n",
       "       [[4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7]]])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[ 1.6971655  2.9445994  4.9434905  7.257107 ]\n",
    " [ 4.436798   9.061197  11.678692  12.575489 ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SeriesPredictor:\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.seq_size=seq_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.W_out = tf.Variable(tf.random_normal([hidden_dim,1]),name='W_out')\n",
    "        self.b_out = tf.Variable(tf.random_normal([1]),name='b_out')\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "        \n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.square(self.model()-self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        :param x: inputs of size [T, batch_size, input_size]\n",
    "        :param W: matrix of fully-connected output layer weights\n",
    "        :param b: vector of fully-connected output layer biases\n",
    "        \"\"\"\n",
    "        cell = rnn.BasicLSTMCell(self.hidden_dim)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out,0), [num_examples,1,1])\n",
    "        out = tf.matmul(outputs, W_repeated)+self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "    \n",
    "    def train(self, train_x, train_y):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(1000):\n",
    "                _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "                if i% 100 == 0:\n",
    "                    print(i,mse)\n",
    "            save_path = self.saver.save(sess,'./model.ckpt')\n",
    "            print('Model saved to {}'.format(save_path))\n",
    "                \n",
    "        \n",
    "    def test(self,test_x):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            self.saver.restore(sess, './model.ckpt')\n",
    "            output = sess.run(self.model(), feed_dict={self.x: test_x})\n",
    "            print(output)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SeriesPredictor:\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.seq_size=seq_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.W_out = tf.get_variable(\"Wout\",initializer=tf.random_normal([hidden_dim,1]))\n",
    "        self.b_out = tf.get_variable(\"b_out\",initializer=tf.random_normal([1]))\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "        \n",
    "        self.mymodel = self.model()\n",
    "        self.cost = tf.reduce_mean(tf.square(self.mymodel-self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        :param x: inputs of size [T, batch_size, input_size]\n",
    "        :param W: matrix of fully-connected output layer weights\n",
    "        :param b: vector of fully-connected output layer biases\n",
    "        \"\"\"\n",
    "        cell = rnn.BasicLSTMCell(self.hidden_dim)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out,0), [num_examples,1,1])\n",
    "        out = tf.matmul(outputs, W_repeated)+self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "    \n",
    "    def train(self, train_x, train_y):\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(1000):\n",
    "            _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "            if i% 100 == 0:\n",
    "                print(i,mse)\n",
    "        return sess\n",
    "                \n",
    "        \n",
    "    def test(self,sess,test_x):        \n",
    "        output = sess.run(self.mymodel, feed_dict={self.x: test_x})\n",
    "        print(output)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 104.54908)\n",
      "(100, 49.596928)\n",
      "(200, 13.441304)\n",
      "(300, 4.84034)\n",
      "(400, 3.223334)\n",
      "(500, 2.582983)\n",
      "(600, 1.9891154)\n",
      "(700, 1.4041783)\n",
      "(800, 1.0117636)\n",
      "(900, 0.73919386)\n",
      "[[ 0.69609344  2.6687462   5.052478    6.9160995 ]\n",
      " [ 4.0849714   9.2390785  11.849617   12.85392   ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "predictor = SeriesPredictor(input_dim=1, seq_size=4, hidden_dim=10)\n",
    "train_x = [[[1], [2], [5], [6]],\n",
    "          [[5], [7], [7], [8]],\n",
    "          [[3], [4], [5], [7]]]\n",
    "train_y = [[1, 3, 7, 11],\n",
    "           [5, 12, 14, 15],\n",
    "           [3, 7, 9, 12]]\n",
    "sess=predictor.train(train_x, train_y)\n",
    "\n",
    "test_x = [[[1], [2], [3], [4]],\n",
    "          [[4], [5], [6], [7]]]\n",
    "\n",
    "predictor.test(sess,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2], [5], [6]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
